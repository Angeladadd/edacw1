- name: Run spark-submit
  shell: |
    spark-submit \
    --master yarn \
    --deploy-mode cluster \
    --py-files {{ ppl_path }}/utils.zip \
    --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
    --conf spark.executor.cores=1 \
    --conf spark.executor.memory=12g \
    {{ ppl_path }}/pipeline.py \
    {{ dataset }} {{ s3_url }} {{ access_key }} {{ secret_key }} \
    {{ input_bucket }} {{ output_bucket }} \
    {{ summary_bucket}} {{ summary_key }} {{ mean_key }} \
    {{ script_args }} 2>&1
  register: spark_submit_output

- name: Extract application ID
  set_fact:
    spark_application_id: "{{ spark_submit_output.stdout | regex_search('application_[0-9_]+') }}"

- name: Show Spark UI URL
  debug:
    msg: "Track running job on Spark UI: {{ yarn_url }}/proxy/{{ spark_application_id }}"
- name: Show Spark History URL
  debug:
    msg: "Track complete jobs on Spark History Server: {{ sparkhistory_url }}"